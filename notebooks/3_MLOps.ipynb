{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbc39c8",
   "metadata": {},
   "source": [
    "# 3. MLOps and Operationalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b500c051",
   "metadata": {},
   "source": [
    "## 3.1 Overview of the MLOps stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4febf0d",
   "metadata": {},
   "source": [
    "This notebook constitutes the third part of the project, following the exploratory analysis performed in the [first notebook](1_EDA.ipynb) and the modeling study developed in the [second notebook](2_models.ipynb). After examining the datasetâ€™s characteristics and evaluating a range of deep learning architectures, we now focus on the operational dimension of the workflow.\n",
    "\n",
    "The objective of this notebook is to document the MLOps components that support the training, tracking, reproducibility, and deployment of the image classification system built for the Food-101 dataset. These elements form the infrastructure that enables systematic experimentation, consistent execution across environments, reliable versioning, and accessible model demonstration.\n",
    "\n",
    "We begin by examining how experiment tracking is handled through MLflow, including the logging of metrics, artifacts, and model signatures during training. We then describe the role of containerisation using Docker to ensure reproducible environments and controlled execution. The continuous integration and delivery pipeline is presented next, highlighting how automated testing and image publication maintain code quality and operational consistency. Finally, we detail the Streamlit-based demo that provides an interactive interface for running inference on new images using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d0d5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 14.0.2 (20251019.1705)\n",
       " -->\n",
       "<!-- Title: mlops_overview Pages: 1 -->\n",
       "<svg width=\"513pt\" height=\"687pt\"\n",
       " viewBox=\"7.00 7.00 506.00 680.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(36 650.98)\">\n",
       "<title>mlops_overview</title>\n",
       "<polygon fill=\"#0d1b2a\" stroke=\"none\" points=\"-28.8,28.8 -28.8,-643.78 469.71,-643.78 469.71,28.8 -28.8,28.8\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_tracking</title>\n",
       "<polygon fill=\"#0d1b2a\" stroke=\"black\" points=\"162.91,-337.98 162.91,-395.48 432.91,-395.48 432.91,-337.98 162.91,-337.98\"/>\n",
       "</g>\n",
       "<!-- data -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>data</title>\n",
       "<polygon fill=\"#0d1b2a\" stroke=\"#cccccc\" stroke-width=\"1.2\" points=\"195.41,-614.98 192.41,-618.98 171.41,-618.98 168.41,-614.98 92.41,-614.98 92.41,-573.98 195.41,-573.98 195.41,-614.98\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"143.91\" y=\"-597.68\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">Food&#45;101 data</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"143.91\" y=\"-581.18\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">(images, labels)</text>\n",
       "</g>\n",
       "<!-- code -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>code</title>\n",
       "<polygon fill=\"#0d1b2a\" stroke=\"#cccccc\" stroke-width=\"1.2\" points=\"189.78,-513.48 98.03,-513.48 98.03,-509.48 94.03,-509.48 94.03,-505.48 98.03,-505.48 98.03,-463.98 94.03,-463.98 94.03,-459.98 98.03,-459.98 98.03,-455.98 189.78,-455.98 189.78,-513.48\"/>\n",
       "<polyline fill=\"none\" stroke=\"#cccccc\" stroke-width=\"1.2\" points=\"98.03,-509.48 102.03,-509.48 102.03,-505.48 98.03,-505.48\"/>\n",
       "<polyline fill=\"none\" stroke=\"#cccccc\" stroke-width=\"1.2\" points=\"98.03,-463.98 102.03,-463.98 102.03,-459.98 98.03,-459.98\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"143.91\" y=\"-496.18\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">Training code</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"143.91\" y=\"-479.68\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">src/</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"143.91\" y=\"-463.18\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">configs/</text>\n",
       "</g>\n",
       "<!-- data&#45;&gt;code -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>data&#45;&gt;code</title>\n",
       "<path fill=\"none\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" d=\"M143.91,-573.47C143.91,-559.95 143.91,-541.65 143.91,-525.26\"/>\n",
       "<polygon fill=\"#2a3f5f\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" points=\"147.41,-525.43 143.91,-515.43 140.41,-525.43 147.41,-525.43\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"164.91\" y=\"-538.68\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">used by</text>\n",
       "</g>\n",
       "<!-- github -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>github</title>\n",
       "<polygon fill=\"#0d1b2a\" stroke=\"#cccccc\" stroke-width=\"1.2\" points=\"134.41,-395.48 31.41,-395.48 31.41,-399.48 19.41,-399.48 19.41,-337.98 134.41,-337.98 134.41,-395.48\"/>\n",
       "<polyline fill=\"none\" stroke=\"#cccccc\" stroke-width=\"1.2\" points=\"19.41,-395.48 31.41,-395.48\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"76.91\" y=\"-378.18\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">GitHub repository</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"76.91\" y=\"-361.68\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">(code, configs,</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"76.91\" y=\"-345.18\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">workflows)</text>\n",
       "</g>\n",
       "<!-- code&#45;&gt;github -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>code&#45;&gt;github</title>\n",
       "<path fill=\"none\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" d=\"M116.72,-455.61C111.08,-448.87 105.54,-441.45 101.16,-433.98 96.22,-425.57 92.01,-415.98 88.55,-406.76\"/>\n",
       "<polygon fill=\"#2a3f5f\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" points=\"91.87,-405.65 85.26,-397.37 85.27,-407.97 91.87,-405.65\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"134.53\" y=\"-420.68\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">versioned in</text>\n",
       "</g>\n",
       "<!-- artifacts -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>artifacts</title>\n",
       "<polygon fill=\"#0d1b2a\" stroke=\"#cccccc\" stroke-width=\"1.2\" points=\"262.53,-395.48 167.28,-395.48 163.28,-391.48 163.28,-337.98 258.53,-337.98 262.53,-341.98 262.53,-395.48\"/>\n",
       "<polyline fill=\"none\" stroke=\"#cccccc\" stroke-width=\"1.2\" points=\"258.53,-391.48 163.28,-391.48\"/>\n",
       "<polyline fill=\"none\" stroke=\"#cccccc\" stroke-width=\"1.2\" points=\"258.53,-391.48 258.53,-337.98\"/>\n",
       "<polyline fill=\"none\" stroke=\"#cccccc\" stroke-width=\"1.2\" points=\"258.53,-391.48 262.53,-395.48\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"212.91\" y=\"-378.18\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">Model artifacts</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"212.91\" y=\"-361.68\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">(checkpoints,</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"212.91\" y=\"-345.18\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">metrics, plots)</text>\n",
       "</g>\n",
       "<!-- code&#45;&gt;artifacts -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>code&#45;&gt;artifacts</title>\n",
       "<path fill=\"none\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" d=\"M160.61,-455.65C169.53,-440.66 180.63,-421.99 190.31,-405.72\"/>\n",
       "<polygon fill=\"#2a3f5f\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" points=\"193.16,-407.77 195.27,-397.39 187.15,-404.19 193.16,-407.77\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"206.91\" y=\"-420.68\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">produces</text>\n",
       "</g>\n",
       "<!-- mlflow -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>mlflow</title>\n",
       "<path fill=\"#0d1b2a\" stroke=\"#cccccc\" stroke-width=\"1.2\" d=\"M432.78,-389.8C432.78,-392.62 408.19,-394.92 377.91,-394.92 347.63,-394.92 323.03,-392.62 323.03,-389.8 323.03,-389.8 323.03,-343.67 323.03,-343.67 323.03,-340.84 347.63,-338.55 377.91,-338.55 408.19,-338.55 432.78,-340.84 432.78,-343.67 432.78,-343.67 432.78,-389.8 432.78,-389.8\"/>\n",
       "<path fill=\"none\" stroke=\"#cccccc\" stroke-width=\"1.2\" d=\"M432.78,-389.8C432.78,-386.97 408.19,-384.67 377.91,-384.67 347.63,-384.67 323.03,-386.97 323.03,-389.8\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"377.91\" y=\"-369.93\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">MLflow tracking</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"377.91\" y=\"-353.43\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">server</text>\n",
       "</g>\n",
       "<!-- code&#45;&gt;mlflow -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>code&#45;&gt;mlflow</title>\n",
       "<path fill=\"none\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" d=\"M190.14,-460.81C226.09,-443 276.31,-418.1 315.77,-398.54\"/>\n",
       "<polygon fill=\"#2a3f5f\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" points=\"317.17,-401.75 324.58,-394.17 314.07,-395.47 317.17,-401.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"293.29\" y=\"-420.68\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">logs to</text>\n",
       "</g>\n",
       "<!-- ci -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>ci</title>\n",
       "<ellipse fill=\"#0d1b2a\" stroke=\"#cccccc\" stroke-width=\"1.2\" cx=\"82.91\" cy=\"-231.99\" rx=\"82.91\" ry=\"28.99\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"82.91\" y=\"-235.19\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">CI/CD workflow</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"82.91\" y=\"-218.69\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">(tests, build, push)</text>\n",
       "</g>\n",
       "<!-- github&#45;&gt;ci -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>github&#45;&gt;ci</title>\n",
       "<path fill=\"none\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" d=\"M78.18,-337.58C79.03,-318.79 80.16,-293.8 81.1,-272.96\"/>\n",
       "<polygon fill=\"#2a3f5f\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" points=\"84.59,-273.37 81.54,-263.22 77.59,-273.05 84.59,-273.37\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"109.5\" y=\"-302.68\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">on push</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"109.5\" y=\"-286.18\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">or commit</text>\n",
       "</g>\n",
       "<!-- docker -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>docker</title>\n",
       "<path fill=\"#0d1b2a\" stroke=\"#cccccc\" stroke-width=\"1.2\" d=\"M145.16,-142.5C145.16,-142.5 70.66,-142.5 70.66,-142.5 64.66,-142.5 58.66,-136.5 58.66,-130.5 58.66,-130.5 58.66,-113.5 58.66,-113.5 58.66,-107.5 64.66,-101.5 70.66,-101.5 70.66,-101.5 145.16,-101.5 145.16,-101.5 151.16,-101.5 157.16,-107.5 157.16,-113.5 157.16,-113.5 157.16,-130.5 157.16,-130.5 157.16,-136.5 151.16,-142.5 145.16,-142.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"107.91\" y=\"-125.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">Docker images</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"107.91\" y=\"-108.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">(app, training)</text>\n",
       "</g>\n",
       "<!-- ci&#45;&gt;docker -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>ci&#45;&gt;docker</title>\n",
       "<path fill=\"none\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" d=\"M87.05,-202.67C89.01,-190.8 91.6,-176.91 94.66,-164.5 95.52,-161.01 96.52,-157.39 97.57,-153.81\"/>\n",
       "<polygon fill=\"#2a3f5f\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" points=\"100.91,-154.87 100.53,-144.28 94.22,-152.79 100.91,-154.87\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"134.78\" y=\"-167.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">build and push</text>\n",
       "</g>\n",
       "<!-- demo -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>demo</title>\n",
       "<polygon fill=\"#0d1b2a\" stroke=\"#cccccc\" stroke-width=\"1.2\" points=\"255.28,-41 160.53,-41 160.53,0 261.28,0 261.28,-35 255.28,-41\"/>\n",
       "<polyline fill=\"none\" stroke=\"#cccccc\" stroke-width=\"1.2\" points=\"255.28,-41 255.28,-35\"/>\n",
       "<polyline fill=\"none\" stroke=\"#cccccc\" stroke-width=\"1.2\" points=\"261.28,-35 255.28,-35\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"210.91\" y=\"-23.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">Streamlit demo</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"210.91\" y=\"-7.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">app.py</text>\n",
       "</g>\n",
       "<!-- docker&#45;&gt;demo -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>docker&#45;&gt;demo</title>\n",
       "<path fill=\"none\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" d=\"M127.47,-100.91C138.55,-89.64 152.74,-75.4 165.66,-63 170.27,-58.57 175.21,-53.94 180.06,-49.44\"/>\n",
       "<polygon fill=\"#2a3f5f\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" points=\"182.41,-52.04 187.4,-42.69 177.67,-46.89 182.41,-52.04\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"177.28\" y=\"-66.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">runs</text>\n",
       "</g>\n",
       "<!-- user -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>user</title>\n",
       "<ellipse fill=\"#0d1b2a\" stroke=\"#cccccc\" stroke-width=\"1.2\" cx=\"282.91\" cy=\"-122\" rx=\"28.32\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"282.91\" y=\"-116.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">User</text>\n",
       "</g>\n",
       "<!-- user&#45;&gt;demo -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>user&#45;&gt;demo</title>\n",
       "<path fill=\"none\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" d=\"M271.34,-105.01C260.81,-90.46 244.99,-68.61 232.19,-50.9\"/>\n",
       "<polygon fill=\"#2a3f5f\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" points=\"235.11,-48.97 226.41,-42.92 229.43,-53.07 235.11,-48.97\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"262.84\" y=\"-66.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">uses</text>\n",
       "</g>\n",
       "<!-- artifacts&#45;&gt;demo -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>artifacts&#45;&gt;demo</title>\n",
       "<path fill=\"none\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" d=\"M212.74,-337.56C212.37,-273.92 211.48,-119.42 211.09,-52.86\"/>\n",
       "<polygon fill=\"#2a3f5f\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" points=\"214.59,-53.14 211.03,-43.16 207.59,-53.18 214.59,-53.14\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"245.19\" y=\"-167.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">loads model</text>\n",
       "</g>\n",
       "<!-- mlflow&#45;&gt;artifacts -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>mlflow&#45;&gt;artifacts</title>\n",
       "<path fill=\"none\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" d=\"M322.65,-366.73C307.1,-366.73 290.08,-366.73 274.19,-366.73\"/>\n",
       "<polygon fill=\"#2a3f5f\" stroke=\"#2a3f5f\" stroke-width=\"1.1\" points=\"274.53,-363.23 264.53,-366.73 274.53,-370.23 274.53,-363.23\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"292.78\" y=\"-372.93\" font-family=\"Times New Roman,serif\" font-size=\"14.00\" fill=\"#ffffff\">stores</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1ddc0856850>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "from src.notebook.mlops_utils import build_mlops_overview_graph\n",
    "build_mlops_overview_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769a9038",
   "metadata": {},
   "source": [
    "The diagram provides a high-level view of the operational workflow supporting the Food-101 image classification project. It complements the modelling work presented in the earlier notebooks by illustrating how the different components interact during development, training, experiment tracking, and deployment.\n",
    "\n",
    "At the top of the workflow, the training code consumes the Food-101 dataset to produce model artifacts such as checkpoints, metrics, and diagnostic plots. These artifacts form the core outputs of each experiment. In parallel, the same training process logs metadata, parameters, and evaluation results to the MLflow tracking server, which serves as a structured record of all experiments. MLflow therefore maintains both the descriptive metadata of each run and, through its coupling with the filesystem, the storage of the generated artifacts.\n",
    "\n",
    "The training code is versioned in a GitHub repository. Any change pushed to the repository automatically triggers the continuous integration and delivery workflow. This pipeline runs tests, validates the environment, and builds Docker images that encapsulate the application and its dependencies. The resulting container images are then published for use in deployment.\n",
    "\n",
    "The Streamlit demo relies on two elements: the Docker image that packages the application logic and environment, and the model artifacts produced during training. Once deployed, the demo enables a user to interact with the trained model through a simple interface, performing inference on new images. In this way, the diagram captures the full MLOps loop, linking data, code, experiment tracking, reproducible environments, automated validation, and user-facing deployment within a coherent operational structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6be01f",
   "metadata": {},
   "source": [
    "## 3.2 Experiment tracking with MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ebe82b",
   "metadata": {},
   "source": [
    "MLflow is used throughout this project to record model configurations, monitor training performance, and store model artifacts in a unified tracking system. This enables systematic comparison of multiple experiments and ensures that each trained model can be retrieved and reproduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b504795a",
   "metadata": {},
   "source": [
    "### 3.2.1 Configuration and MLflow Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad9fdb",
   "metadata": {},
   "source": [
    "Experiment tracking is enabled directly within the training script through parameters defined in the configuration files located in the ```configs``` directory. These parameters specify the tracking server address, the experiment name, the run name, and optional tags describing the context of a run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a33ae3f",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# Content from configs/train.yaml\n",
    "arch: \"resnet50\"\n",
    "pretrained: true\n",
    "\n",
    "data_folder: ./data/food-101\n",
    "batch_size: 64\n",
    "epochs: 10\n",
    "lr: 3e-4\n",
    "weight_decay: 0.01\n",
    "num_workers: 4\n",
    "freeze_backbone: false\n",
    "device: cuda\n",
    "seed: 3\n",
    "\n",
    "mlflow: true\n",
    "mlflow_experiment: \"Image-Classification\"\n",
    "mlflow_tracking_uri: \"file:./mlruns\"\n",
    "mlflow_tags:\n",
    "  dataset: \"food101\"\n",
    "  stage: \"dev\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb763ac2",
   "metadata": {},
   "source": [
    "The MLflow tracking server is deployed as part of the Docker Compose environment. It operates with a local SQLite backend for run metadata and a mounted file directory for artifact storage. This setup provides persistence of results across sessions and establishes a clear separation between the application and the tracking infrastructure. The following elements define the tracking environment:\n",
    "\n",
    "- **Tracking URI**: Specifies the backend store and artifact root used by MLflow. It is read by the training script through the configuration file.\n",
    "\n",
    "- **Experiment and run metadata**: Each training session is assigned to a named experiment. Within that experiment, individual runs are uniquely identified and can be enriched with descriptive tags.\n",
    "\n",
    "- **Artifact management**: All generated outputs, including the trained model, plots, and associated metrics, are stored in the artifact repository. This ensures that every model version can be recovered and inspected in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d915b16a",
   "metadata": {},
   "source": [
    "```docker-compose.yml\n",
    "services:\n",
    "  mlflow:\n",
    "    image: ghcr.io/mlflow/mlflow:latest\n",
    "    command: >\n",
    "      mlflow server\n",
    "      --host 0.0.0.0\n",
    "      --port 5000\n",
    "      --backend-store-uri sqlite:///mlflow.db\n",
    "      --default-artifact-root file:/mlruns\n",
    "    ports:\n",
    "      - \"5000:5000\"\n",
    "    volumes:\n",
    "      - ./mlruns:/mlruns\n",
    "      - ./mlflow.db:/mlflow.db\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18621639",
   "metadata": {},
   "source": [
    "In addition to the Docker based deployment, the MLflow UI can also be launched locally without containers. In that case, the tracking URI specified in `configs/train.yaml` still points to the same backend store and artifact directory, and a developer can start the interface with a command such as:\n",
    "\n",
    "```\n",
    "mlflow ui \\\n",
    "  --backend-store-uri file:./mlruns \\\n",
    "  --default-artifact-root file:./mlruns \\\n",
    "  --host 127.0.0.1 \\\n",
    "  --port 5000 \\\n",
    "  --workers 1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9493ce",
   "metadata": {},
   "source": [
    "This configuration allows the training process to automatically register performance data and artifacts without modifying the experimental workflow described in the previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cde13b",
   "metadata": {},
   "source": [
    "### 3.2.2 Logging from the training script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355d4e5e",
   "metadata": {},
   "source": [
    "MLflow logging is integrated directly into the training workflow in ```src/train.py```. When enabled in the configuration, a tracking run is created at the start of the script, and key elements of the experiment are recorded throughout execution.\n",
    "\n",
    "At initialisation, the script logs the most relevant parameters that define the training context from the ```configs/train.yaml```, including model architecture, batch size, learning rate, number of epochs, and whether pretrained weights are used. Any tags specified in the configuration are also attached to the run to facilitate filtering and comparison between experiments.\n",
    "\n",
    "The evaluation metrics are implemented in the training engine located in ```src/engine.py```. A wide range of indicators is computed during validation to capture both classification performance and prediction reliability. Among these metrics, the most important include:\n",
    "- **Top-N accuracies**, with Top 1 as the primary reference\n",
    "- **ROC AUC, Precision, Recall, and F1 score**, computed both per class and as micro and macro averages\n",
    "- The **confusion matrix**, which highlights systematic misclassifications between classes\n",
    "- Calibration oriented measures such as the **reliability diagram** and the **confidence histogram**, used to assess how well predicted probabilities reflect true correctness\n",
    "\n",
    "During training, performance is monitored continuously. For each epoch, both training and validation metrics are logged, in particular the loss and Top 1 accuracy values. These metrics are stored with the current epoch index, enabling the visual inspection of learning curves directly in the MLflow interface.\n",
    "\n",
    "At validation checkpoints, the script evaluates the model on the validation set and logs the resulting metrics and diagnostic outputs. When a new best performance is observed, the corresponding model checkpoint is saved and registered as an artifact, ensuring that the best model from every run can be retrieved at any time.\n",
    "\n",
    "Through this automated logging mechanism, model performance, hyperparameters, and key artifacts are consistently recorded, enabling reliable comparison, reproducibility, and traceability across training experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0367f9",
   "metadata": {},
   "source": [
    "### 3.2.3 Browsing and comparing runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af2f9e5",
   "metadata": {},
   "source": [
    "Once training traces and artifacts are logged, experiments can be inspected directly within the MLflow interface. The tracking UI provides a centralised view of all recorded runs, allowing the comparison of models based on their configuration, performance metrics, and generated outputs.\n",
    "\n",
    "Each run is associated with the experiment defined in the configuration. Within this experiment, runs are displayed alongside their key characteristics, such as the model architecture, the number of trainable parameters, and the use of pretrained weights. Metrics recorded at the end of training, such as Top 1 validation accuracy, serve as primary indicators when benchmarking different configurations.\n",
    "\n",
    "The UI enables sorting and filtering based on any logged parameter or tag. This facilitates targeted analyses, for example isolating only the frozen-backbone models or only the configurations involving a specific architecture family. Selecting an individual run reveals the full set of logged metrics, visual learning curves across epochs, and all diagnostic artifacts produced during validation.\n",
    "\n",
    "For the best model of each experiment, the registered checkpoint can be downloaded for inference or reloaded directly from MLflow, ensuring that every trained variant remains accessible. This ability to track results over time, inspect their evolution, and retrieve the exact version of a model that achieved them forms a key part of experiment governance in the workflow.\n",
    "\n",
    "Through this interface, the comparison of multiple training strategies becomes straightforward, supporting the selection of model candidates for further evaluation and deployment in the subsequent stages of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c838975c",
   "metadata": {},
   "source": [
    "## 3.3 Interactive demo with Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1633e6",
   "metadata": {},
   "source": [
    "The user facing part of the project is implemented as a Streamlit application defined in ```app.py```, with styling rules in ```styles.py```. This demo provides an accessible interface to the trained model and constitutes the final stage of the workflow, where the Food 101 classifier is exposed as an interactive tool rather than as a script or a notebook. As mentionned in the [previous notebook](2_models.ipynb), the model used is **Swin_t** as it is a good trade off between performances and scalability.\n",
    "\n",
    "The application runs on top of the same inference utilities as the evaluation code. The model is loaded through ```load_model_and_meta```, which reconstructs both the architecture and the class vocabulary from a checkpoint, and predictions are obtained with predict_pil followed by ```topk_labels```. This ensures that the behaviour of the demo remains consistent with the training and validation pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486e00f8",
   "metadata": {},
   "source": [
    "![screenshot_streamlit](../figures/screenshot_streamlit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2587436",
   "metadata": {},
   "source": [
    "### 3.3.1 User interaction and prediction workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9e092b",
   "metadata": {},
   "source": [
    "The application is structured around a single task: allowing a user to upload a food image and obtain a prediction from the deployed classifier. Once an image is provided, it is preprocessed using the same transformations as in training, passed through the model, and evaluated to produce Top k class probabilities. The three most likely classes are displayed prominently, together with a short textual indication of prediction confidence to support interpretation.\n",
    "\n",
    "A visual preview of the uploaded image is presented alongside the results, and additional contextual elements describe the overall performance expected from the model. This allows users to assess outputs not only in terms of predicted labels but also in relation to the reliability demonstrated during validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bbeeeb",
   "metadata": {},
   "source": [
    "In addition to running the application locally, a hosted instance of the demo is available on Hugging Face Spaces:\n",
    "\n",
    "https://kevinhuads-deepvision-workflow.hf.space/\n",
    "\n",
    "This Space is configured as a Docker Space and uses the same container image and entry point described in the Docker section of this notebook, so its behaviour mirrors the containerised local deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f18da9",
   "metadata": {},
   "source": [
    "### 3.3.2 Efficient model loading and consistency with training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494c5e9a",
   "metadata": {},
   "source": [
    "The model is loaded once and kept in memory throughout the session to ensure a responsive experience. The checkpoint path can be set through an environment variable, which enables the demo to be used with different model versions without modifying the code. All inference logic is shared with the evaluation pipeline, guaranteeing alignment between the behaviour observed in this interface and the behaviour analysed during training and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a3f857",
   "metadata": {},
   "source": [
    "## 3.4 Reproducible environments with Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eabd312",
   "metadata": {},
   "source": [
    "To ensure that the system behaves consistently across machines and over time, the project is packaged as a set of Docker services. This encapsulates both the Streamlit application and the MLflow tracking server in controlled environments, so that the results presented in this notebook can be reproduced with the same dependencies, configuration, and runtime behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d10bd01",
   "metadata": {},
   "source": [
    "### 3.4.1 Application container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c0a4e8",
   "metadata": {},
   "source": [
    "In ```Dockerfile```, we build an application container from a lightweight Python base image and contains everything needed to run the Streamlit demo and the associated inference code. The Dockerfile installs the system tools required to compile Python packages, upgrades pip, installs the project dependencies from the same requirements file used in continuous integration, and then installs the repository itself in editable mode.\n",
    "\n",
    "The working directory is set to the project root inside the container, and the entry command directly launches the Streamlit server on port 8501. Environment variables control how Streamlit runs, including headless mode and the maximum upload size, so that the container can be started without additional flags. In effect, the image acts as a portable runtime for the demo: once built, it can be executed on any host with Docker installed, without manual Python setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87562ff",
   "metadata": {},
   "source": [
    "```Dockerfile\n",
    "FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
    "    build-essential \\\n",
    "    curl \\\n",
    "  && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Copy dependency file(s) and install runtime deps first (cache-friendly)\n",
    "COPY requirements-ci.txt /app/requirements.txt\n",
    "RUN pip install --upgrade pip\n",
    "RUN pip install -r /app/requirements.txt\n",
    "\n",
    "# Copy whole repository (so editable install can see package source)\n",
    "COPY . /app\n",
    "\n",
    "# Install project in editable mode now that source is present\n",
    "RUN pip install -e .\n",
    "\n",
    "EXPOSE 8501\n",
    "\n",
    "CMD [\"streamlit\", \"run\", \"app.py\", \"--server.port\", \n",
    "     \"8501\", \"--server.headless\", \"true\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bd9450",
   "metadata": {},
   "source": [
    "### 3.4.2 MLflow tracking service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c1250e",
   "metadata": {},
   "source": [
    "Experiment tracking is handled by a dedicated MLflow service defined in the Docker Compose configuration. Instead of running MLflow locally in an ad hoc manner, the project uses an official MLflow image configured as a tracking server with a SQLite backend and a file based artifact store.\n",
    "\n",
    "The metadata database and the artifact directory are mounted as volumes from the host into the container. This means that all runs, metrics, and model artifacts persist across container restarts and remain visible to both the training scripts and the demo. The server listens on port 5000 and exposes the tracking API and user interface, matching the tracking URI and artifact root configured in the training configuration files.\n",
    "\n",
    "By isolating MLflow in its own service, the tracking infrastructure is separated from the application logic while remaining fully accessible to the rest of the stack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67794b62",
   "metadata": {},
   "source": [
    "### 3.4.3 Orchestrating the stack with Docker Compose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dcb42f",
   "metadata": {},
   "source": [
    "```docker-compose.yml``` is used to start the application and the MLflow server together as a single stack. The Compose file defines two services:\n",
    "\n",
    "- an `app` service, built from the Dockerfile in the repository and exposing the Streamlit interface on port 8501\n",
    "- an `mlflow` service, running the tracking server on port 5000 and mounting the shared mlruns and mlflow.db volumes\n",
    "\n",
    "Port mappings make both the demo and the tracking UI reachable from the host, and the filesystem bindings ensure that training runs and artifacts created outside the containers remain visible inside them. The application can therefore read checkpoints from the same directory structure that MLflow uses to store models.\n",
    "\n",
    "With this arrangement, the complete environment described in this notebook can be recreated by building the application image and starting the Compose stack. The containers provide a stable, self contained runtime for the classifier, the tracking server, and the interactive demo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d5d47b",
   "metadata": {},
   "source": [
    "## 3.5 Continuous Integration and Continuous Delivery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25108cd",
   "metadata": {},
   "source": [
    "With ```.github/workflows/cicd.yml``` the repository is equipped with a CI/CD pipeline that validates each change to the codebase and automates the production of Docker images for the application. This pipeline connects the development process with the containerised environment described in the previous section, ensuring that any image used in deployment corresponds to code that has passed the test suite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99273017",
   "metadata": {},
   "source": [
    "### 3.5.1 Automated tests for each change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1fa72e",
   "metadata": {},
   "source": [
    "The first job of the workflow is a continuous integration stage that runs on every push and pull request targeting the main branch. It uses a Linux runner with Python 3.11 and performs a series of steps that mirror the local development setup:\n",
    "\n",
    "- The repository is checked out at the current commit.\n",
    "- The requested Python version is installed and a pip cache is configured to reduce installation time across runs.\n",
    "- The dependencies listed in `requirements-ci.txt` are installed, followed by an editable installation of the project itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8119169",
   "metadata": {},
   "source": [
    "Once the environment is prepared, the workflow runs the test suite with `pytest`, measuring coverage on the src package and exporting an XML coverage report. This stage acts as a quality gate: only commits that satisfy the tests and maintain the integrity of the core codebase proceed to the subsequent build phase. Amongst the tests scripts, we have:\n",
    "\n",
    "- **test_cli_parse_only.py**: Checks that the CLI commands parse arguments and run without errors in dry mode.\n",
    "- **test_config_and_imports.py**: Verifies that core modules import correctly and that the project structure is recognised.\n",
    "- **test_data_contract.py**: Confirms that dataset builders and transform factories exist and expose a valid interface.\n",
    "- **test_data_runtime.py**: Validates that datasets and transforms work at runtime on a minimal sample.\n",
    "- **test_infer_api_contract.py**: Ensures a public inference entry point is available and rejects invalid input.\n",
    "- **test_infer_runtime.py**: Exercises the inference pipeline end to end and checks output format and sorting.\n",
    "- **test_metrics_correctness.py**: Verifies correctness of the accuracy computation and probability handling.\n",
    "- **test_project_smoke.py**: Smoke tests the main entry points (`train`, `eval`, `infer`, `app`).\n",
    "- **test_train_happy_path.py**: Runs a minimal training loop to confirm that training completes and artifacts are produced.\n",
    "- **conftest.py**: Provides shared test configuration and ensures modules can be imported.\n",
    "\n",
    "By enforcing these checks on both direct pushes and pull requests, the pipeline maintains a consistent standard of correctness on the main branch, which is the branch used as the reference for experiments and deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851cb6d0",
   "metadata": {},
   "source": [
    "### 3.5.2 Building and publishing Docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bb9479",
   "metadata": {},
   "source": [
    "The second job in the workflow is responsible for continuous delivery. It is triggered only for pushes on `main` and is configured to run only after the test job has completed successfully. This guarantees that Docker images are built exclusively from commits that have passed the CI stage.\n",
    "\n",
    "The job starts by checking out the repository, then authenticates to Docker Hub using credentials stored as encrypted GitHub secrets. It invokes the Docker build and push action on the project root, using the Dockerfile presented in section 3.4 to produce the application image.\n",
    "\n",
    "Two tags are applied to the resulting image:\n",
    "\n",
    "- a `latest` tag, which always points to the most recent successful build on `main`\n",
    "- a tag based on the Git commit hash, which uniquely identifies the code version used to build the image\n",
    "\n",
    "These tags provide a direct link between a running container and the exact state of the repository from which it was produced. The same image can then be used in local Docker Compose runs or deployed in a more formal environment.\n",
    "\n",
    "This results in a public Docker image being available at kevinhuads/deepvision-workflow:latest, which anyone can pull with: `docker pull kevinhuads/deepvision-workflow:latest`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0512de82",
   "metadata": {},
   "source": [
    "![cicd_workflow](../figures/cicd_workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35661e06",
   "metadata": {},
   "source": [
    "### 3.5.3 Role in the overall workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a32014a",
   "metadata": {},
   "source": [
    "The CI/CD pipeline ties together the different elements of the project lifecycle. The tests validate that the training code, evaluation logic, and Streamlit application remain consistent after each modification. The build and push stage then captures this validated state as a versioned Docker image that can be started together with the MLflow tracking service.\n",
    "\n",
    "As a result, there is a continuous chain from the experiments tracked in MLflow, through the trained models served by the Streamlit demo, to the container images produced by the workflow. This chain provides a clear mapping between code, configuration, experiments, and deployed artefacts for the Food 101 classification system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15138d0c",
   "metadata": {},
   "source": [
    "## 3.6 Limitations and scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60777f1",
   "metadata": {},
   "source": [
    "The workflow described in this notebook provides an end to end path from data exploration to a tracked and containerised demo of the Food 101 classifier. It remains, however, intentionally scoped to a single project and a single dataset, with several simplifying assumptions.\n",
    "\n",
    "The main limitations are the following:\n",
    "\n",
    "- **Dataset and data management**: The pipeline is designed specifically for Food 101 and does not include a general mechanism for handling multiple datasets, dataset versioning, or integration with a dedicated data catalogue or feature store. Dataset identity is managed through configuration files and MLflow tags.\n",
    "\n",
    "- **Training scale and orchestration**: Training is executed on a single machine, optionally with GPU support. Distributed training, job scheduling, and resource orchestration are not addressed, and hyperparameter exploration relies on manually defined configurations rather than an automated optimisation service.\n",
    "\n",
    "- **Tracking infrastructure**: The MLflow server is configured with a local SQLite backend and a file based artifact store. This setup is suitable for individual use or small projects but does not provide features such as authentication, fine grained access control, or high availability typically required in multi user production environments.\n",
    "\n",
    "- **Deployment model**: Deployment is represented by a Streamlit application running in a Docker container. The project does not expose a separate inference API, load balanced serving layer, or dedicated monitoring of latency, throughput, and error rates. The demo is oriented toward interactive single image inspection rather than large scale production traffic.\n",
    "\n",
    "- **Continuous integration and delivery**: The CI/CD pipeline focuses on unit and integration tests for the Python codebase and on building versioned Docker images. It does not currently include automated tests of the running containers, end to end checks of the web interface, or promotion workflows between distinct deployment environments.\n",
    "\n",
    "These constraints define the practical envelope within which the system operates and clarify the context in which the reported experimental results and the deployed demo should be interpreted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (food-venv)",
   "language": "python",
   "name": "food-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
